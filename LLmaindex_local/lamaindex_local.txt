import os
import json
import time
import logging
from typing import List

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)

log = logging.getLogger("rag-fast")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# RAG imports
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings
from llama_index.llms.google_genai import GoogleGenAI
from llama_index.embeddings.google_genai import GoogleGenAIEmbedding

GEMINI_API_KEY = ""

Settings.log_level = "INFO"

index = None
llm_fast = None   # fast LLM instance


# --------------------------
# MODELS
# --------------------------

class QuizRequest(BaseModel):
    topic: str
    difficulty: str

class Answer(BaseModel):
    selected: str
    correct: str

class ScoreRequest(BaseModel):
    answers: List[Answer]


# --------------------------
# CLEAN JSON
# --------------------------

def clean_json(txt):
    txt = txt.replace("```json", "").replace("```", "").strip()
    try:
        return json.loads(txt)
    except:
        if "[" in txt and "]" in txt:
            try:
                sub = txt[txt.index("[") : txt.rindex("]") + 1]
                return json.loads(sub)
            except:
                pass
        return None


# --------------------------
# FAST LLM CALL (WORKING)
# --------------------------

async def llm_call_fast(prompt: str):
    global llm_fast

    if llm_fast is None:
        llm_fast = GoogleGenAI(
            model="models/gemini-2.0-flash-lite",
            api_key=GEMINI_API_KEY
        )

    start = time.perf_counter()

    res = await llm_fast.acomplete(prompt)
    text = res.text

    duration = round(time.perf_counter() - start, 4)
    log.info(f"âš¡ FAST LLM Time: {duration} sec")

    return text


# --------------------------
# STARTUP â†’ BUILD EMBEDDINGS
# --------------------------

@app.on_event("startup")
async def startup_event():
    global index

    try:
        log.info("ðŸ“‚ Loading documents from /pdfs ...")

        if not os.path.exists("pdfs"):
            os.makedirs("pdfs")

        docs = SimpleDirectoryReader(
            "pdfs", required_exts=[".pdf", ".txt"]
        ).load_data()

        log.info(f"ðŸ§  Generating embeddings for {len(docs)} documents...")

        embed = GoogleGenAIEmbedding(
            model="models/text-embedding-004",
            api_key=GEMINI_API_KEY
        )

        start = time.perf_counter()

        index = VectorStoreIndex.from_documents(
            docs,
            embed_model=embed
        )

        duration = round(time.perf_counter() - start, 4)
        log.info(f"âœ… Embeddings completed in {duration} seconds")
        log.info(f"ðŸ“Œ Vector store: {type(index._vector_store)}")
        log.info("âœ¨ FAST RAG Engine Ready")

    except Exception as e:
        log.error("Fatal startup error:", exc_info=True)
        raise


# --------------------------
# GET TOPICS
# --------------------------

@app.get("/topics")
async def get_topics():
    prompt = """
    Return a JSON array of chemistry topics.
    Example: ["Organic Chemistry", "Inorganic Chemistry"]
    """

    try:
        raw = await llm_call_fast(prompt)
        data = clean_json(raw)

        if data:
            return {"topics": data}

        return {"topics": ["Fallback Topic"]}

    except Exception as e:
        log.error("Topic retrieval error:", exc_info=True)
        return {"topics": ["Fallback Topic"]}


# --------------------------
# GENERATE QUIZ (WITH RETRIEVAL TIME)
# --------------------------

@app.post("/start_quiz")
async def start_quiz(req: QuizRequest):
    global index

    # ----------------------
    # 1. RAG RETRIEVAL TIME
    # ----------------------
    try:
        retriever = index.as_retriever(similarity_top_k=5)

        start_ret = time.perf_counter()
        nodes = retriever.retrieve(req.topic)
        retrieval_time = round(time.perf_counter() - start_ret, 4)

        log.info(f"ðŸ”Ž RAG Retrieval Time: {retrieval_time} sec")
        log.info(f"ðŸ“š Retrieved {len(nodes)} nodes")

    except Exception as e:
        log.error("Retrieval error:", exc_info=True)
        retrieval_time = None
        nodes = []

    # ----------------------
    # 2. LLM QUIZ GENERATION
    # ----------------------
    prompt = f"""
    Generate 10 MCQ questions in JSON format.

    Topic: "{req.topic}"
    Difficulty: "{req.difficulty}"

    Use the following context if relevant:
    { [n.text for n in nodes] }

    Format:
    [
      {{"q": "...", "A": "...", "B": "...", "C": "...", "D": "...", "correct": "A"}}
    ]
    """

    try:
        raw = await llm_call_fast(prompt)
        quiz = clean_json(raw)

        if quiz and len(quiz) == 10:
            return {
                "quiz": quiz,
                "retrieval_time": retrieval_time
            }

        raise HTTPException(status_code=500, detail="Invalid quiz JSON")

    except Exception as e:
        log.error("Quiz error:", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# --------------------------
# SCORE
# --------------------------

@app.post("/final_score")
async def final_score(req: ScoreRequest):
    score = sum(1 for x in req.answers if x.selected == x.correct)
    return {"score": score, "total": len(req.answers)}